{
 "metadata": {
  "name": "",
  "signature": "sha256:059a1a2041bad37978644b51a0f5e6be168a5b4dd0c1c6eb94335a74868f8456"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "with open('picklefiles/user_1.pck', 'r') as picklefile:\n",
      "    data = pickle.load(picklefile)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "no_apostros = {\n",
      "    \"'\": \"\",\n",
      "    \"\\'\": \"\", \n",
      "    \"\\n\": \" \",\n",
      "    \"&\": \"and\"\n",
      "}\n",
      "\n",
      "apostros_re = re.compile('(%s)' % '|'.join(no_apostros.keys()))\n",
      "def no_apostrophes(s, no_apostros=no_apostros):\n",
      "     def replace(match):\n",
      "         return no_apostros[match.group(0)]\n",
      "     return apostros_re.sub(replace, s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user = defaultdict(list)\n",
      "for d in data:\n",
      "    user[d['stars']].append( no_apostrophes(((d['text'].split('\\n\\nReturn Factor')[0]).lower()).replace('\\n\\n', ' '))  )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gensim"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = []\n",
      "for i in range(1,6):\n",
      "    documents.append(' '.join(d for d in user[i]))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(documents[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "339341"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove common words and tokenize\n",
      "from nltk.corpus import stopwords\n",
      "#stoplist = set('for a of the and to in'.split())\n",
      "stoplist = stopwords.words('english')\n",
      "texts = [[word for word in document.split() if word not in stoplist]\n",
      "          for document in documents]\n",
      "print len(texts)\n",
      "\n",
      "# remove words that appear only once\n",
      "all_tokens = sum(texts, [])\n",
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) <= 2)\n",
      "texts = [[word for word in text if word not in tokens_once]\n",
      "          for text in texts]\n",
      "print len(texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for t in texts:\n",
      "    print len(t)\n",
      "print len(tokens_once)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1125\n",
        "8722\n",
        "26502\n",
        "47666\n",
        "16250\n",
        "15380\n"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = gensim.corpora.Dictionary(texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(5268 unique tokens: [u'limited', u'prices,', u'todays', u'mid-week', u'update.']...)\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(text) for text in texts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.9, max_features = 7000)\n",
      "X = vectorizer.fit_transform(documents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = gensim.matutils.Sparse2Corpus(X.transpose())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "id2words = {}\n",
      "for i, word in enumerate(vectorizer.get_feature_names()):\n",
      "    id2words[i] = word"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model = gensim.models.ldamodel.LdaModel(corpus, id2word=id2words, num_topics=4, passes=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = gensim.models.hdpmodel.HdpModel(corpus, id2word=id2words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i,topic in enumerate(model.show_topics(formatted=False)):\n",
      "    print 'TOPIC', i\n",
      "    for val, word in topic:\n",
      "        print '%f \\t %s' % (val, word)\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TOPIC 0\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "'int' object is not iterable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-136-ce83bd374707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'TOPIC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'%f \\t %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in corpus:\n",
      "    print model[doc]\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0.028694280580101303), (9, 0.040089378421291684), (10, 0.25478433304460979), (13, 0.53576441152184628), (15, 0.14028262447469178)]\n",
        "\n",
        "[(0, 0.011448470328305748), (13, 0.96698865750272978)]\n",
        "\n",
        "[(10, 0.041124762995659279), (13, 0.93682391589064995)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "[(0, 0.019581603952535609), (10, 0.11758551783864621), (13, 0.82858831836233537), (14, 0.02146434084956832)]\n",
        "\n",
        "[(10, 0.048417323567848836), (13, 0.66155481707366837), (14, 0.28142876079944701)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 74
    }
   ],
   "metadata": {}
  }
 ]
}